    1  sudo nmuti
    2  sudo nmtui
    3  sudo apt update
    4  sudo apt upgrade
    5  sudo shutdown now
    6  sudo apt install xrdp
    7  sudo nano /boot/firmware/cmdline.txt
    8  sudo cat  /boot/firmware/cmdline.txt
    9  sudo reboot now
   10  sudo curl -sSL https://get.docker.com | sh
   11  sudo usermod -aG docker pi
   12  sudo apt install docker-compose
   13  sudo reboot now
   14  curl -sfL https://get.k3s.io | sh -s - --write-kubeconfig-mode 644
   15  sudo reboot now
   16  sudo apt update 
   17  sudo apt upgrade
   18  kubectl get nodes
   19  sudo reboot now
   20  sudo shutdown now
   21  sudo cat /var/lib/rancher/k3s/server/node-token
   22  kubectl get nodes
   23  sudo cat /var/lib/rancher/k3s/server/node-token
   24  kubectl get nodes
   25  sudo apt update
   26  sudo apt install snapd
   27  sudo reboot now
   28  sudo snap install snapd
   29  sudo snap install k9s
   30  k9s
   31  sudo apt update
   32  sudo apt install -y qemu-user-static binfmt-support
   33  sudo dpkg --add-architecture amd64
   34  sudo apt update
   35  sudo apt install libc6:amd64
   36  sudo apt update
   37  sudo apt install -y qemu-user-static binfmt-support
   38  sudo dpkg --add-architecture amd64
   39  sudo apt update
   40  sudo apt install libc6:amd64
   41  mkdir ~/.kube
   42  sudo cp /etc/rancher/k3s/k3s.yaml ~/.kube/config && sudo chown $USER ~/.kube/config
   43  sudo chmod 600 ~/.kube/config && export KUBECONFIG=~/.kube/config
   44  sudo reboot now
   45  k9s
   46  mkdir ~/.kube
   47  sudo cp /etc/rancher/k3s/k3s.yaml ~/.kube/config && sudo chown $USER ~/.kube/config
   48  sudo chmod 600 ~/.kube/config && export KUBECONFIG=~/.kube/config
   49  k9s
   50  mkdir ~/k9s-installation
   51  cd ~/k9s-installation
   52  curl -LO https://github.com/derailed/k9s/releases/download/v0.32.4/k9s_Linux_amd64.tar.gz
   53  tar xf k9s_Linux_amd64.tar.gz
   54  sudo mv k9s /usr/local/bin
   55  mkdir ~/.kube
   56  sudo cp /etc/rancher/k3s/k3s.yaml ~/.kube/config && sudo chown $USER ~/.kube/config
   57  sudo chmod 600 ~/.kube/config && export KUBECONFIG=~/.kube/config
   58  sudot reboot now
   59  k9s
   60  sudo reboot now
   61  kubectl get pods
   62  kubectl get nodes
   63  k9s
   64  docker images
   65  docker ps
   66  kubectl apply -k "github.com/minio/operator?ref=v5.0.15"
   67  ubectl apply -f - <<EOF
   68  apiVersion: v1
   69  kind: Secret
   70  metadata:
   71    name: console-sa-secret
   72    namespace: minio-operator
   73    annotations:
   74      kubernetes.io/service-account.name: console-sa
   75  type: kubernetes.io/service-account-token
   76  EOF
   77  SA_TOKEN=$(kubectl -n minio-operator  get secret console-sa-secret -o jsonpath="{.data.token}" | base64 --decode)
   78  echo $SA_TOKEN
   79  kubectl port-forward svc/console -n minio-operator 9090:9090
   80  helm repo add spark-operator https://googlecloudplatform.github.io/spark-on-k8s-operator
   81  curl https://baltocdn.com/helm/signing.asc | gpg --dearmor | sudo tee /usr/share/keyrings/helm.gpg > /dev/null
   82  sudo apt-get install apt-transport-https --yes
   83  echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/helm.gpg] https://baltocdn.com/helm/stable/debian/ all main" | sudo tee /etc/apt/sources.list.d/helm-stable-debian.list
   84  sudo apt-get update
   85  sudo apt-get install helm
   86  sudo reboot now
   87  kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.7.0/aio/deploy/recommended.yaml
   88  nano adminuser.yaml
   89  nano cluserrole.yaml
   90  nano secret.yaml
   91  kubectl apply -f adminuser.yaml
   92  kubectl apply -f cluserrole.yaml
   93  kubectl apply -f secret.yaml
   94  kubectl get secret admin-user -n kubernetes-dashboard -o jsonpath={".data.token"} | base64 -d
   95  kubectl proxy
   96  kubectl det nodes
   97  kubectl get nodes
   98  helm repo add spark-operator https://googlecloudplatform.github.io/spark-on-k8s-operator
   99  k9s
  100  sudo apt update
  101  sudo apt upgrade
  102  java -version
  103  java location
  104  which java
  105  cd /usr/bin/java
  106  cd /usr/bin/java/
  107  cd ..
  108  ls
  109  cd /usr/bin/java/
  110  cd /usr/bin/java
  111  cd /usr/
  112  cd /bin/
  113  ls
  114  cd /java/
  115  cd java/
  116  ls
  117  cd ..
  118  ls
  119  cd /usr
  120  cd /local
  121  cd /local/
  122  ls
  123  cd local.
  124  cd local/
  125  ls
  126  which java
  127  cd  ..
  128  cd ..
  129  ls
  130  cd usr/
  131  ls
  132  cd lib/
  133  lssssssssssssssssssss
  134  ls
  135  cd jvm/
  136  ls
  137  cd ..
  138  ls
  139  cd local/
  140  ls
  141  spark-submit
  142  sudo reboot now
  143  kubectl delete --all pods --namespace=default
  144  $ kubectl delete pod my-sparkoperator-59bccd4598-qsjw9 my-sparkoperator-crd-cleanup-hjzrk -n default --grace-period 0
  145  $ kubectl delete pods my-sparkoperator-59bccd4598-qsjw9 my-sparkoperator-crd-cleanup-hjzrk -n default --grace-period 0
  146  $ kubectl delete pods my-sparkoperator-59bccd4598-qsjw9 my-sparkoperator-crd-cleanup-hjzrk -n default
  147  kubectl delete pods my-sparkoperator-59bccd4598-qsjw9 my-sparkoperator-crd-cleanup-hjzrk -n default --grace-period 0
  148  kubectl get all -A
  149  ls
  150  cd ..
  151  ls
  152  cd ..
  153  ls
  154  cd usr/
  155  ls
  156  cd local/
  157  ls
  158  cd ..
  159  ls
  160  cd home/
  161  ls
  162  cd pi
  163  ls
  164  cd download
  165  cd /usr/local/
  166  ls
  167  cd /download/
  168  cd /downloads/
  169  ls
  170  cd ..
  171  cd home/
  172  cd pi/
  173  cd downlods
  174  ls
  175  cd Downloads/
  176  ls
  177  sudo tar xfz spark-3.5.2-bin-hadoop3.tgz -c /usr/local/
  178  sudo tar xfz spark-3.5.2-bin-hadoop3.tgz -C /usr/local/
  179  cd /usr/local/
  180  ls
  181  ln -sT spark-3.5.2-bin-hadoop3 spark
  182  sudo ln -sT spark-3.5.2-bin-hadoop3 spark
  183  ls
  184  spark-submit
  185  nano ~/shrc
  186  nano ~/.bashrc
  187  sudo apt-get install default-jdk
  188  java      -version
  189  nano ~/.bashrc
  190  spark-submit
  191  which spark
  192  java versionn
  193  java version
  194  java      -version
  195  nano ~/.bashrc
  196  spark-submit
  197  helm repo add spark-operator https://googlecloudplatform.github.io/spark-on-k8s-operator
  198  helm install spark-operator spark-operator/spark-operator     --namespace spark-operator     --create-namespace
  199  helm --version
  200  helm --v
  201  helm -version
  202  helm
  203  helm repo add apache-airflow https://airflow.apache.org
  204  helm repo update
  205  helm repo add spark-operator https://googlecloudplatform.github.io/spark-on-k8s-operator
  206  helm version
  207  helm repo add spark-operator https://googlecloudplatform.github.io/spark-on-k8s-operator
  208  helm repo add spark-operator https://github.com/kubeflow/spark-operator/releases/tag/spark-operator-chart-1.1.27
  209  helm install my-release spark-operator/spark-operator --namespace spark-operator --create-namespace --set webhook.enable=true
  210  helm repo add spark-operator https://googlecloudplatform.github.io/spark-on-k8s-operator
  211  nano jupyter.yaml
  212  kubectl apply -f jupyter.yaml
  213  helm repo add cloudnativeapp https://cloudnativeapp.github.io/charts/curated/
  214  helm install my-sparkoperator cloudnativeapp/sparkoperator --version 0.2.3
  215  helm uninstall my-sparkoperator cloudnativeapp/sparkoperator --version 0.2.3
  216  helm uninstall my-sparkoperator cloudnativeapp/sparkoperator
  217  kubectl delete pod my-sparkoperator-crd-cleanup-w2rf8 my-sparkoperator cloudnativeapp/sparkoperator
  218  kubectl delete pod my-sparkoperator-crd-cleanup-w2rf8 -n default
  219  kubectl delete pod my-sparkoperator-59bccd4598-vmvwf --namespace default --grace-period 0 --force
  220  kubectl delete pods my-sparkoperator-crd-cleanup-xzgdg --namespace default --grace-period 0 --force
  221  k9s
  222  helm uninstall my-sparkoperator cloudnativeapp/sparkoperator
  223  kubectl delete -n default
  224  kubectl delete namespace default
  225  kubectl delete deployment my-sparkoperator
  226  kubectl proxy
  227  kubectl create namespace spark-operator
  228  helm repo add spark-operator https://googlecloudplatform.github.io/spark-on-k8s-operator
  229  helm repo add spark-operator https://kubeflow.github.io/spark-operator
  230  helm install spark-operator spark-operator/spark-operator     --namespace spark-operator     --create-namespace
  231  spark-sumit
  232  spark-submit
  233  ls
  234  cd /usr/
  235  ls
  236  cd local
  237  ls
  238  spark-submit
  239  cd ..
  240  ls
  241  cd bin/
  242  ls
  243  spark-submit
  244  cd spark
  245  cd ..
  246  ls
  247  cd usr/
  248  ls
  249  cd local/
  250  ls
  251  cd spark-3.5.2-bin-hadoop3/
  252  ls
  253  cd bin/
  254  ls
  255  spark=submit
  256  spark-submit
  257  spark-shell
  258  ls
  259  pwd
  260  spark-shell
  261  spark
  262  sudo reboot
  263  nano ~/.bashrc
  264  spark-submit
  265  nano ~/.bashrc
  266  spark-submit
  267  nano ~/.bashrc
  268  source .bashrc
  269  source ~/.bashrc
  270  nano ~/.bashrc
  271  source ~/.bashrc
  272  nano ~/.bashrc
  273  source ~/.bashrc
  274  nano ~/.bashrc
  275  source ~/.bashrc
  276  spark-shell
  277  nano ~/.bashrc
  278  source ~/.bashrc
  279  nano ~/.bashrc
  280  source ~/.bashrc
  281  nano ~/.bashrc
  282  source ~/.bashrc
  283  nano ~/.bashrc
  284  source ~/.bashrc
  285  nano ~/.bashrc
  286  source ~/.bashrc
  287  nano ~/.bashrc
  288  source ~/.bashrc
  289  spark-submit
  290  spark-shell
  291  nano ~/.bashrc
  292  spark-shell
  293  cd Downloads/
  294  ls
  295  mv aws-java-sdk-bundle-1.12.276.jar /usr/local/spark/jars/
  296  ls
  297  mv hadoop-aws-3.3.4.jar /usr/local/spark/jars/
  298  ls
  299  cd /usr/local/spark/jars/
  300  ls
  301  cd ..
  302  ls
  303  cd jars/
  304  ls
  305  code .
  306  code .
  307  k9s
  308  ls -lhrt
  309  time
  310  date
  311  spark-submit
  312  nano ~/.bashrc
  313  source ~/.bashrc
  314  spark-submit
  315  k9s
  316  which java
  317  cd /usr/lib/jvm/
  318  ls
  319  pwd
  320  python --version
  321  spark
  322  spark --version
  323  kubectl get nodes
  324  k9s
  325  sudo reboot now
  326  ./spark-submit --deploy-mode cluster --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark --conf spark.kubernetes.container.image.pullPolicy=Always --conf spark.hadoop.fs.s3a.path.style.access=True --conf spark.hadoop.fs.s3a.access.key=WKpCKYo5nx3n9hnUzlYs --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem --conf spark.hadoop.fs.s3a.secret.key=BAyGGngWAu9zGytn6W0HR4seOoX5GDVQ1v3T83c1 --conf spark.hadoop.fs.s3a.path.style.access=True --conf spark.hadoop.fs.s3a.connection.ssl.enabled=False --conf spark.hadoop.fs.s3a.endpoint=http://s3a-hl.s3a:9000 --conf spark.kubernetes.container.image=sonusukralia/spark:1.1 --conf spark.master=k8s://https://127.0.0.1:6443 local:///app/main1.py
  327  spark-submit --deploy-mode cluster --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark --conf spark.kubernetes.container.image.pullPolicy=Always --conf spark.hadoop.fs.s3a.path.style.access=True --conf spark.hadoop.fs.s3a.access.key=WKpCKYo5nx3n9hnUzlYs --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem --conf spark.hadoop.fs.s3a.secret.key=BAyGGngWAu9zGytn6W0HR4seOoX5GDVQ1v3T83c1 --conf spark.hadoop.fs.s3a.path.style.access=True --conf spark.hadoop.fs.s3a.connection.ssl.enabled=False --conf spark.hadoop.fs.s3a.endpoint=http://s3a-hl.s3a:9000 --conf spark.kubernetes.container.image=sonusukralia/spark:1.1 --conf spark.master=k8s://https://127.0.0.1:6443 local:///app/main1.py
  328  spark-submit --deploy-mode cluster --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark --conf spark.kubernetes.container.image.pullPolicy=Always --conf spark.hadoop.fs.s3a.path.style.access=True --conf spark.hadoop.fs.s3a.access.key=uigAG5Xcr2vO4wWqHJ2H --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem --conf spark.hadoop.fs.s3a.secret.key=Zz5b6F4SbJstaSPXuyoZvfpMNIiTAvDAVqot4fOQ --conf spark.hadoop.fs.s3a.path.style.access=True --conf spark.hadoop.fs.s3a.connection.ssl.enabled=False --conf spark.hadoop.fs.s3a.endpoint=http://s3a-hl.s3a:9000 --conf spark.kubernetes.container.image=sonusukralia/spark:1.1 --conf spark.master=k8s://https://127.0.0.1:6443 local:///app/main1.py
  329  code .
  330  k9s
  331  kubectl get nodes
  332  kubectl proxy
  333  docker build -t sonusukralia/spark:1.3 .
  334  SA_TOKEN=$(kubectl -n minio-operator  get secret console-sa-secret -o jsonpath="{.data.token}" | base64 --decode)
  335  echo $SA_TOKEN
  336  spark-submit --deploy-mode cluster --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark --conf spark.kubernetes.container.image.pullPolicy=Always --conf spark.hadoop.fs.s3a.path.style.access=True --conf spark.hadoop.fs.s3a.access.key=l9clBhS80ZudADoDQnSS --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem --conf spark.hadoop.fs.s3a.secret.key=5mU3bwzCDejg8aR3qgqwK0eVEsk8gUyxW0p0Cz6h --conf spark.hadoop.fs.s3a.path.style.access=True --conf spark.hadoop.fs.s3a.connection.ssl.enabled=False --conf spark.hadoop.fs.s3a.endpoint=http://s3a-hl.s3a:9000 --conf spark.kubernetes.container.image=sonusukralia/spark:1.1 --conf spark.master=k8s://https://127.0.0.1:6443 local:///app/main1.py
  337  history > aug18
